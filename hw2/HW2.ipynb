{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkANmyasP2bY",
        "colab_type": "text"
      },
      "source": [
        "# Q1: Scalar Computation Graph and Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ6_aDcWQYg3",
        "colab_type": "text"
      },
      "source": [
        "## TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rgc6AVBQXQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def g_w1(x1: float, x2: float, w1: float, w2: float) -> float:\n",
        "    g = 0\n",
        "    E = np.exp(-w1*x1-w2*x2)\n",
        "    g = (x1*E)/(1+E)**2 + w1\n",
        "    return g\n",
        "\n",
        "def g_w2(x1: float, x2: float, w1: float, w2: float) -> float:\n",
        "    g = 0\n",
        "    E = np.exp(-w1*x1-w2*x2)\n",
        "    g = (x2*E)/(1+E)**2 + w2\n",
        "    return g\n",
        "\n",
        "def g_x1(x1: float, x2: float, w1: float, w2: float) -> float:\n",
        "    g = 0\n",
        "    E = np.exp(-w1*x1-w2*x2)\n",
        "    g = (w1*E)/(1+E)**2 \n",
        "    return g\n",
        "\n",
        "def g_x2(x1: float, x2: float, w1: float, w2: float) -> float:\n",
        "    g = 0\n",
        "    E = np.exp(-w1*x1-w2*x2)\n",
        "    g = (w2*E)/(1+E)**2 \n",
        "    return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFLw7UolQIe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "b6323345-7d58-4c33-f712-53db52fa603a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x1 = 0.2\n",
        "x2 = 0.4\n",
        "w1 = 0.3\n",
        "w2 = -0.5\n",
        "\n",
        "grads_x1 = []\n",
        "grads_x2 = []\n",
        "grads_w1 = []\n",
        "grads_w2 = []\n",
        "w1s = [w1]\n",
        "w2s = [w2]\n",
        "\n",
        "for i in range(30):\n",
        "    grad_w1 = g_w1(x1, x2, w1, w2)    \n",
        "    grad_w2 = g_w2(x1, x2, w1, w2)\n",
        "    \n",
        "    w2 += -0.01 * grad_w2\n",
        "    w1 += -0.01 * grad_w1\n",
        "    \n",
        "    w1s.append(w1)\n",
        "    w2s.append(w2)\n",
        "\n",
        "    grads_w1.append(grad_w1)\n",
        "    grads_w2.append(grad_w2)\n",
        "it=[i for i in range(30)]\n",
        "plt.plot(it, grads_w1, color=\"r\", linestyle=\"-\", marker=\"^\", linewidth=1)\n",
        "plt.plot(it, grads_w2, color=\"b\", linestyle=\"-\", marker=\"s\", linewidth=1)\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"grads\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAsH7KUcQp8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8V5EPucOdwu",
        "colab_type": "text"
      },
      "source": [
        "# Q3: Neural Network From Scratch\n",
        "\n",
        "In this section, we will implement a neural network to solve MNIST, a hand-written digits (0-9) classification dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eS5VOSqPUgu",
        "colab_type": "text"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNQLW-GH1bX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Dict\n",
        "from functools import partial\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.monitor_interval = 0\n",
        "tqdm = partial(tqdm, bar_format='{l_bar}{r_bar}')\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSRfAdmy1uhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SIZE = 50_000\n",
        "\n",
        "train = torchvision.datasets.MNIST('./data', train=True, transform=None, target_transform=None, download=True)\n",
        "test = torchvision.datasets.MNIST('./data', train=False, transform=None, target_transform=None, download=True)\n",
        "\n",
        "train_x = train.data.float().numpy()\n",
        "train_y = train.targets.numpy()\n",
        "\n",
        "shuffle_idx = np.arange(len(train_x))\n",
        "np.random.RandomState(0).shuffle(shuffle_idx)\n",
        "train_x = train_x[shuffle_idx]\n",
        "train_y = train_y[shuffle_idx]\n",
        "\n",
        "dev_x, dev_y = train_x[TRAIN_SIZE:], train_y[TRAIN_SIZE:]\n",
        "train_x, train_y = train_x[:TRAIN_SIZE], train_y[:TRAIN_SIZE]\n",
        "\n",
        "test_x = test.data.float().numpy()\n",
        "test_y = test.targets.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GSBMEzy7sIV",
        "colab_type": "text"
      },
      "source": [
        "Sample of images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRPzeyY-7a5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "d637a2d8-2469-4ff6-9583-925fefe267aa"
      },
      "source": [
        "i = 4048 #@param {type: \"slider\", min: 0, max: 10000}\n",
        "print(f'label = {train_y[i]}')\n",
        "plt.imshow(train_x[i])\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3gT0+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDrCxDQD8XfX",
        "colab_type": "text"
      },
      "source": [
        "Each images have the same shape of 28-by-28. We flatten the matrix and pretend it is just one long vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owHStQK_7UTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_FEAT = 28 * 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq9_DDRf4Gli",
        "colab_type": "text"
      },
      "source": [
        "Normalize the feature. Note that we only use the training set to compute the mean and standard derivation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkumLLwa2DP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_x.mean()\n",
        "std = train_x.std()\n",
        "\n",
        "train_x = (train_x - mean) / (std + 1e-7)\n",
        "dev_x = (dev_x - mean) / (std + 1e-7)\n",
        "test_x = (test_x - mean) / (std + 1e-7)\n",
        "\n",
        "train_x = train_x.reshape(-1, NB_FEAT)\n",
        "dev_x = dev_x.reshape(-1, NB_FEAT)\n",
        "test_x = test_x.reshape(-1, NB_FEAT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNa2DCck51Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def row_logsumexp(x):\n",
        "    # numerical stablization\n",
        "    x_max = x.max(axis=1).reshape(-1, 1)\n",
        "    return x_max + np.log(np.exp(x - x_max).sum(axis=1)).reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdk_ER0rPKBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.param: Dict[str, np.ndarray] = {}\n",
        "        self.grad: Dict[str, np.ndarray] = {}\n",
        "\n",
        "    def set_param(self, key: str, param: np.ndarray):\n",
        "        self.param[key] = param\n",
        "        self.grad[key] = np.zeros_like(param)\n",
        "\n",
        "    def get_param(self, key):\n",
        "        assert key in self.param, f'variable {key} is not part of the Parameter'\n",
        "        return self.param[key]\n",
        "\n",
        "    def accumlate_grad(self, key: str, grad: np.ndarray):\n",
        "        assert key in self.param, f'variable {key} is not part of the Parameter'\n",
        "        assert self.param[key].shape == grad.shape, f'for variable {key}, the shape of parameter and the shape of gradient is not matched'\n",
        "        self.grad[key] += grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for key in self.param:\n",
        "            self.grad[key] = np.zeros_like(self.param[key])\n",
        "\n",
        "    def apply_grad(self, lr: float):\n",
        "        for key in self.param.keys():\n",
        "            assert self.param[key].shape == self.grad[key].shape, f'for variable {key}, the shape of parameter and the shape of gradient is not matched'\n",
        "            self.param[key] -= self.grad[key] * lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCPh5O_PKKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_linear(input_dim, output_dim):\n",
        "    return np.random.RandomState(0).randn(input_dim, output_dim) * np.sqrt(2 / input_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkH7YxnoZ96D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main_training(params: Parameters, forward_and_backward, train_x, train_y, dev_x, dev_y, batch_size, learning_rate, nb_epochs,acc_list):#@\n",
        "    assert isinstance(params, Parameters)\n",
        "    step = 0\n",
        "    best_acc = 0\n",
        "    for epoch in tqdm(range(nb_epochs)):\n",
        "        train_loss = []\n",
        "        lr = learning_rate\n",
        "        for i in range(0, len(train_x), batch_size):\n",
        "            batch_x = train_x[i:i+batch_size]\n",
        "            batch_y = train_y[i:i+batch_size]\n",
        "\n",
        "            loss, probs = forward_and_backward(batch_x, batch_y, params)\n",
        "            params.apply_grad(lr)\n",
        "\n",
        "            train_loss.append(loss)\n",
        "            step += 1\n",
        "\n",
        "        accs = []\n",
        "        for i in range(0, len(dev_x), batch_size):\n",
        "            batch_x = dev_x[i:i+batch_size]\n",
        "            batch_y = dev_y[i:i+batch_size]\n",
        "\n",
        "            loss, probs = forward_and_backward(batch_x, batch_y, params, grad=False)\n",
        "            pred_y = probs.argmax(axis=1)\n",
        "            accs.append(pred_y == batch_y)\n",
        "        acc = np.mean(accs) * 100\n",
        "        acc_list.append(float(acc))#@\n",
        "        print(f'epoch {epoch} train loss = {np.mean(train_loss):.3f} dev accuracy = {acc:.2f}%')\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "  \n",
        "    print(f'best dev accuracy = {best_acc:.2f}%')\n",
        "    return acc_list#@"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KslzAMpabAiV",
        "colab_type": "text"
      },
      "source": [
        "## Q2.1 Linear Classifier\n",
        "\n",
        "Let $x \\in R^{1\\times N}$ be a single sample. $N$ is the number of the feature dimension and $C$ is the number of class in the final classification. Note $N=28*28$ and $C=10$\n",
        "\n",
        "In the softmax layer, $W_{sm} \\in R^{N \\times C}$. The unnormalized score $s \\in R^{C}$ is\n",
        "\n",
        "$$s = x\\cdot W_{sm}$$\n",
        "\n",
        "With softmax function, we get the probability $p(c_i)$ of class $i$ where $i \\in \\{1,\\cdots,C\\}$\n",
        "\n",
        "$$p(c_i) = \\frac {\\exp(s_i)} {\\sum_i \\exp(s_i)}$$\n",
        "\n",
        "where $s_i$ is the $i^{th}$ element of $s$.\n",
        "\n",
        "Assuming $y \\in \\{1,\\cdots,C\\}$, we want to minimize $-\\log p(c_y)$, the cross-entropy loss between one hot true distribution `q(c_i) = 1 if i == y else 0` and $p(c_i)$.\n",
        "\n",
        "We will take the average $-\\log p(c_y)$ of a batch of x as the loss.\n",
        "\n",
        "In `linear_classifier_forward_and_backward`, `batch_x` and `batch_y` are matrixs, where each row are $x$ and $y$, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAD_MC9lbELf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_classifier = Parameters()\n",
        "linear_classifier.set_param('w_sm', init_linear(NB_FEAT, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpjfQEn_xjI6",
        "colab_type": "text"
      },
      "source": [
        "### TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aICn5CtgbMMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_classifier_forward_and_backward(batch_x, batch_y, param: Parameters, grad=True) -> (float, np.ndarray):\n",
        "    '''\n",
        "    compute the loss and the gradient of each parameter\n",
        "    return loss (float) and probs p(c_i) (matrix with shape batch_size x C)\n",
        "    '''\n",
        "    param.zero_grad()\n",
        "    w_sm = param.get_param('w_sm')\n",
        "\n",
        "    # compute loss and probs\n",
        "    loss = 0\n",
        "    probs = np.zeros((len(batch_x), 10))\n",
        "\n",
        "    s = np.dot(batch_x,w_sm)\n",
        "    s_exp = np.exp(s)\n",
        "    probs = s_exp/np.sum(s_exp,axis=1,keepdims=True)\n",
        "    log_probs = -np.log(probs[range(len(batch_x)),batch_y])\n",
        "    loss = np.sum(log_probs)/len(batch_x)\n",
        "    if not grad:\n",
        "        return loss, probs\n",
        "\n",
        "    # compute gradient\n",
        "    w_sm_grad = np.zeros_like(w_sm)\n",
        "    d_s = probs\n",
        "    d_s[range(len(batch_x)),batch_y] -= 1\n",
        "    d_s /= len(batch_x)\n",
        "    w_sm_grad = np.dot(batch_x.T,d_s)\n",
        "\n",
        "    # save the gradient\n",
        "    param.accumlate_grad('w_sm', w_sm_grad)\n",
        "    return loss, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbBBpkpbbMz",
        "colab_type": "text"
      },
      "source": [
        "### Loss & Gradient Check\n",
        "\n",
        "If all assertions are passed, it means you are good to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tTXJTrbfek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use a prime number for batch size would make debugging easier\n",
        "bs = 7\n",
        "batch_x = train_x[:bs]\n",
        "batch_y = train_y[:bs]\n",
        "loss, _ = linear_classifier_forward_and_backward(batch_x, batch_y, linear_classifier)\n",
        "\n",
        "w_sm = linear_classifier.get_param('w_sm')\n",
        "_w_sm = torch.tensor(w_sm, dtype=torch.double, requires_grad=True)\n",
        "_batch_x = torch.tensor(batch_x, dtype=torch.double, requires_grad=False)\n",
        "_batch_y = torch.tensor(batch_y, dtype=torch.long, requires_grad=False)\n",
        "\n",
        "_logits = F.linear(_batch_x, _w_sm.T)\n",
        "_logprobs = F.log_softmax(_logits, dim=-1)\n",
        "_loss = -_logprobs[torch.arange(len(_batch_y)), _batch_y].mean()\n",
        "_loss.backward()\n",
        "#assert np.isclose(loss, _loss.item())\n",
        "assert np.allclose(_w_sm.grad.numpy(), linear_classifier.grad['w_sm'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egX8ucvXbsP7",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7C_vFBwbvGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "7d125a49-2f22-47d6-b24c-b40e42e4350f"
      },
      "source": [
        "BS = 50\n",
        "LR = 0.005\n",
        "NB_EPOCH = 20\n",
        "\n",
        "linear_classifier = Parameters()\n",
        "linear_classifier.set_param('w_sm', init_linear(NB_FEAT, 10))\n",
        "acc_list0 = []\n",
        "acc_list0= main_training(linear_classifier, linear_classifier_forward_and_backward, train_x, train_y, dev_x, dev_y, BS, LR, NB_EPOCH,acc_list0)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|| 1/20 [00:01<00:24,  1.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train loss = 0.619 dev accuracy = 87.97%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|| 2/20 [00:02<00:21,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train loss = 0.380 dev accuracy = 89.59%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|| 3/20 [00:03<00:18,  1.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train loss = 0.347 dev accuracy = 90.25%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|| 4/20 [00:03<00:16,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train loss = 0.330 dev accuracy = 90.87%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|| 5/20 [00:04<00:14,  1.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train loss = 0.318 dev accuracy = 91.14%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|| 6/20 [00:05<00:13,  1.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train loss = 0.310 dev accuracy = 91.33%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|| 7/20 [00:06<00:12,  1.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 train loss = 0.304 dev accuracy = 91.48%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|| 8/20 [00:07<00:10,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 train loss = 0.299 dev accuracy = 91.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|| 9/20 [00:08<00:09,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 train loss = 0.295 dev accuracy = 91.60%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|| 10/20 [00:09<00:08,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 train loss = 0.292 dev accuracy = 91.68%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|| 11/20 [00:10<00:07,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 train loss = 0.289 dev accuracy = 91.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|| 12/20 [00:10<00:06,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11 train loss = 0.286 dev accuracy = 91.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|| 13/20 [00:11<00:06,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 train loss = 0.284 dev accuracy = 91.78%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|| 14/20 [00:12<00:05,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 13 train loss = 0.281 dev accuracy = 91.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|| 15/20 [00:13<00:04,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 train loss = 0.280 dev accuracy = 91.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|| 16/20 [00:14<00:03,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 15 train loss = 0.278 dev accuracy = 91.82%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|| 17/20 [00:15<00:02,  1.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 16 train loss = 0.276 dev accuracy = 91.88%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|| 18/20 [00:15<00:01,  1.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 17 train loss = 0.275 dev accuracy = 91.86%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|| 19/20 [00:16<00:00,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 18 train loss = 0.273 dev accuracy = 91.86%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|| 20/20 [00:17<00:00,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 19 train loss = 0.272 dev accuracy = 91.93%\n",
            "best dev accuracy = 91.93%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn7gO3v_RgHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "d2557e8e-1593-4693-cd1d-a2f576e89395"
      },
      "source": [
        "it=[i for i in range(NB_EPOCH)]\n",
        "plt.plot(it, acc_list0, color=\"r\", linestyle=\"-\", marker=\"^\", linewidth=1)\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncoIwM7OSnCDMzKwkJwgzMyvp/wNPnXjocCf4UAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkaYMGxZOqT1",
        "colab_type": "text"
      },
      "source": [
        "## Q2.1 MLP with Single Hidden Layer\n",
        "\n",
        "Let $x \\in R^{1\\times N}$ be a single sample. $N$ is the number of the feature dimension and $C$ is the number of class in the final classification.\n",
        "\n",
        "For the first layer, $W_1 \\in R^{N\\times \\frac{N}{2}}$ and $b_1 \\in R^{\\frac{N}{2}}$\n",
        "\n",
        "$$\\bar{h}_1 = x\\cdot W_1 + b_1$$\n",
        "\n",
        "$$h_1 = ReLU(\\bar{h}_1)$$\n",
        "\n",
        "In the softmax layer, $W_{sm} \\in R^{\\frac{N}{2} \\times C}$. The unnormalized score $s \\in R^{C}$ is\n",
        "\n",
        "$$s = h_1\\cdot W_{sm}$$\n",
        "\n",
        "With softmax function, we get the probability $p(c_i)$ of class $i$ where $i \\in \\{1,\\cdots,C\\}$\n",
        "\n",
        "$$p(c_i) = \\frac {\\exp(s_i)} {\\sum_i \\exp(s_i)}$$\n",
        "\n",
        "where $s_i$ is the $i^{th}$ element of $s$.\n",
        "\n",
        "Assuming $y \\in \\{1,\\cdots,C\\}$, we want to minimize $-\\log p(c_y)$, the cross-entropy loss between one hot true distribution `q(c_i) = 1 if i == y else 0` and $p(c_i)$.\n",
        "\n",
        "We will take the average $-\\log p(c_y)$ of a batch of x as the loss.\n",
        "\n",
        "In `mlp_single_hidden_forward_and_backward`, `batch_x` and `batch_y` are matrixs, where each row are $x$ and $y$, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtO3xNMYRevK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQlWUL_f520s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_single_hidden = Parameters()\n",
        "mlp_single_hidden.set_param('w1', init_linear(NB_FEAT, NB_FEAT // 2))\n",
        "mlp_single_hidden.set_param('b1', np.zeros(NB_FEAT // 2))\n",
        "mlp_single_hidden.set_param('w_sm', init_linear(NB_FEAT // 2, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37K-xIMFxeZo",
        "colab_type": "text"
      },
      "source": [
        "### TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xq8CDgCZYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_single_hidden_forward_and_backward(batch_x, batch_y, param: Parameters, grad=True):\n",
        "    '''\n",
        "    compute the loss and the gradient of each parameter\n",
        "    return loss (float) and p(c_i) (matrix with shape batch_size x C)\n",
        "    '''\n",
        "    param.zero_grad()\n",
        "    w1 = param.get_param('w1')\n",
        "    b1 = param.get_param('b1')\n",
        "    w_sm = param.get_param('w_sm')\n",
        "\n",
        "\n",
        "    # compute loss and probs\n",
        "    loss = 0\n",
        "    probs = np.zeros((len(batch_x), 10))\n",
        "    h1_hat = np.dot(batch_x,w1)+b1\n",
        "    h1 = np.maximum(0,h1_hat)\n",
        "    s = np.dot(h1,w_sm)\n",
        "    s_exp = np.exp(s)\n",
        "    probs = s_exp/np.sum(s_exp,axis = 1,keepdims =True)\n",
        "    log_probs = -np.log(probs[range(len(batch_x)),batch_y])\n",
        "    loss = np.sum(log_probs)/len(batch_x)\n",
        "\n",
        "    if not grad:\n",
        "        return loss, probs\n",
        "\n",
        "    # compute gradient\n",
        "    w1_grad = np.zeros_like(w1)\n",
        "    b1_grad = np.zeros_like(b1)\n",
        "    w_sm_grad = np.zeros_like(w_sm)\n",
        "    d_s = probs\n",
        "    d_s[range(len(h1)),batch_y] -= 1\n",
        "    d_s /= len(h1)\n",
        "    w_sm_grad = np.dot(h1.T,d_s)\n",
        "    d_h1 = np.dot(d_s,w_sm.T)\n",
        "    d_h1[h1<=0]=0\n",
        "    w1_grad = np.dot(batch_x.T,d_h1)\n",
        "    b1_grad = np.sum(d_h1,axis=0,keepdims=True)[0]\n",
        "\n",
        "    param.accumlate_grad('w1', w1_grad)\n",
        "    param.accumlate_grad('b1', b1_grad)\n",
        "    param.accumlate_grad('w_sm', w_sm_grad)\n",
        "    return loss, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vpqro3iO0Am",
        "colab_type": "text"
      },
      "source": [
        "### Loss & Gradient Check\n",
        "\n",
        "If all assertions are passed, it means you are good to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAl0A2_nCx-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use a prime number for batch size would make debugging easier\n",
        "bs = 7\n",
        "batch_x = train_x[:bs]\n",
        "batch_y = train_y[:bs]\n",
        "loss, _ = mlp_single_hidden_forward_and_backward(batch_x, batch_y, mlp_single_hidden)\n",
        "\n",
        "w1 = mlp_single_hidden.get_param('w1')\n",
        "b1 = mlp_single_hidden.get_param('b1')\n",
        "w_sm = mlp_single_hidden.get_param('w_sm')\n",
        "_w1 = torch.tensor(w1, dtype=torch.double, requires_grad=True)\n",
        "_b1 = torch.tensor(b1, dtype=torch.double, requires_grad=True)\n",
        "_w_sm = torch.tensor(w_sm, dtype=torch.double, requires_grad=True)\n",
        "_batch_x = torch.tensor(batch_x, dtype=torch.double, requires_grad=False)\n",
        "_batch_y = torch.tensor(batch_y, dtype=torch.long, requires_grad=False)\n",
        "\n",
        "_h1 = F.linear(_batch_x, _w1.T) + _b1\n",
        "_h1 = F.relu(_h1)\n",
        "_logits = F.linear(_h1, _w_sm.T)\n",
        "_logprobs = F.log_softmax(_logits, dim=-1)\n",
        "_loss = -_logprobs[torch.arange(len(_batch_y)), _batch_y].mean()\n",
        "_loss.backward()\n",
        "\n",
        "assert np.isclose(loss, _loss.item())\n",
        "assert np.allclose(_w_sm.grad.numpy(), mlp_single_hidden.grad['w_sm'])\n",
        "assert np.allclose(_w1.grad.numpy(), mlp_single_hidden.grad['w1'])\n",
        "assert np.allclose(_b1.grad.numpy(), mlp_single_hidden.grad['b1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaEBK2p_azU6",
        "colab_type": "text"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INoZSBXT52_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "f5fae89e-990f-4417-b7e4-72e45bd6f94e"
      },
      "source": [
        "BS = 50\n",
        "LR = 0.005\n",
        "NB_EPOCH = 20\n",
        "\n",
        "mlp_single_hidden = Parameters()\n",
        "mlp_single_hidden.set_param('w1', init_linear(NB_FEAT, NB_FEAT // 2))\n",
        "mlp_single_hidden.set_param('b1', np.zeros(NB_FEAT // 2))\n",
        "mlp_single_hidden.set_param('w_sm', init_linear(NB_FEAT // 2, 10))\n",
        "acc_list1 = []\n",
        "acc_list1 =main_training(mlp_single_hidden, mlp_single_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, BS, LR, NB_EPOCH,acc_list1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|| 1/20 [00:08<02:36,  8.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train loss = 0.533 dev accuracy = 90.39%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|| 2/20 [00:16<02:27,  8.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train loss = 0.293 dev accuracy = 92.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|| 3/20 [00:24<02:20,  8.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train loss = 0.244 dev accuracy = 93.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|| 4/20 [00:32<02:11,  8.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train loss = 0.214 dev accuracy = 94.07%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|| 5/20 [00:41<02:03,  8.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train loss = 0.193 dev accuracy = 94.39%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|| 6/20 [00:49<01:55,  8.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train loss = 0.177 dev accuracy = 94.76%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|| 7/20 [00:57<01:46,  8.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 train loss = 0.163 dev accuracy = 95.08%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|| 8/20 [01:05<01:38,  8.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 train loss = 0.152 dev accuracy = 95.35%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|| 9/20 [01:13<01:29,  8.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 train loss = 0.142 dev accuracy = 95.55%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|| 10/20 [01:22<01:22,  8.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 train loss = 0.134 dev accuracy = 95.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|| 11/20 [01:30<01:14,  8.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 train loss = 0.126 dev accuracy = 95.94%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|| 12/20 [01:38<01:06,  8.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11 train loss = 0.119 dev accuracy = 96.07%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|| 13/20 [01:47<00:58,  8.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 train loss = 0.113 dev accuracy = 96.15%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|| 14/20 [01:56<00:50,  8.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 13 train loss = 0.108 dev accuracy = 96.26%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|| 15/20 [02:04<00:42,  8.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 train loss = 0.103 dev accuracy = 96.40%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|| 16/20 [02:12<00:33,  8.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 15 train loss = 0.098 dev accuracy = 96.52%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|| 17/20 [02:20<00:25,  8.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 16 train loss = 0.094 dev accuracy = 96.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|| 18/20 [02:29<00:16,  8.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 17 train loss = 0.090 dev accuracy = 96.63%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|| 19/20 [02:37<00:08,  8.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 18 train loss = 0.087 dev accuracy = 96.66%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|| 20/20 [02:45<00:00,  8.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 19 train loss = 0.083 dev accuracy = 96.77%\n",
            "best dev accuracy = 96.77%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siWRroXQHSSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8d0609e6-0486-4797-c771-25370b212275"
      },
      "source": [
        "it=[i for i in range(NB_EPOCH)]\n",
        "plt.plot(it, acc_list1, color=\"r\", linestyle=\"-\", marker=\"^\", linewidth=1)\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSvwiIinz/wGUlHiy/jMZMAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ZhYaVwHSRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzyRX0-fcCBs",
        "colab_type": "text"
      },
      "source": [
        "## Q2.3 MLP with Two Hidden Layer\n",
        "\n",
        "Let $x \\in R^{1\\times N}$ be a single sample. $N$ is the number of the feature dimension and $C$ is the number of class in the final classification.\n",
        "\n",
        "For the first layer, $W_1 \\in R^{N\\times \\frac{N}{2}}$ and $b_1 \\in R^{\\frac{N}{2}}$\n",
        "\n",
        "$$\\bar{h}_1 = x\\cdot W_1 + b_1$$\n",
        "\n",
        "$$h_1 = ReLU(\\bar{h}_1)$$\n",
        "\n",
        "For the second layer, $W_2 \\in R^{\\frac{N}{2} \\times \\frac{N}{2}}$ and $b_2 \\in R^{\\frac{N}{2}}$\n",
        "\n",
        "$$\\bar{h}_2 = h_1\\cdot W_2 + b_2$$\n",
        "\n",
        "$$h_2 = h_1 + ReLU(\\bar{h}_2)$$\n",
        "\n",
        "*Sidenote: in deep learning, $g(x, f) = x + f(x)$ is usually referred to as skip connection.*\n",
        "\n",
        "In the softmax layer, $W_{sm} \\in R^{\\frac{N}{2} \\times C}$. The unnormalized score $s \\in R^{C}$ is\n",
        "\n",
        "$$s = h_2\\cdot W_{sm}$$\n",
        "\n",
        "With softmax function, we get the probability $p(c_i)$ of class $i$ where $i \\in \\{1,\\cdots,C\\}$\n",
        "\n",
        "$$p(c_i) = \\frac {\\exp(s_i)} {\\sum_i \\exp(s_i)}$$\n",
        "\n",
        "where $s_i$ is the $i^{th}$ element of $s$.\n",
        "\n",
        "Assuming $y \\in \\{1,\\cdots,C\\}$, we want to minimize $-\\log p(c_y)$, the cross-entropy loss between one hot true distribution `q(c_i) = 1 if i == y else 0` and $p(c_i)$.\n",
        "\n",
        "We will take the average $-\\log p(c_y)$ of a batch of x as the loss.\n",
        "\n",
        "In `mlp_two_hidden_forward_and_backward`, `batch_x` and `batch_y` are matrixs, where each row are $x$ and $y$, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1XBElNccHeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_two_hidden = Parameters()\n",
        "mlp_two_hidden.set_param('w1', init_linear(NB_FEAT, NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('b1', np.zeros(NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('w2', init_linear(NB_FEAT // 2, NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('b2', np.zeros(NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('w_sm', init_linear(NB_FEAT // 2, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiVRXqN4xXgm",
        "colab_type": "text"
      },
      "source": [
        "### TODO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tsJbpmgcHh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_two_hidden_forward_and_backward(batch_x, batch_y, param: Parameters, grad=True):\n",
        "    '''\n",
        "    compute the loss and the gradient of each parameter\n",
        "    return loss (float) and p(c_i) (matrix with shape batch_size x C)\n",
        "    '''\n",
        "    param.zero_grad()\n",
        "    w1 = param.get_param('w1')\n",
        "    b1 = param.get_param('b1')\n",
        "    w2 = param.get_param('w2')\n",
        "    b2 = param.get_param('b2')\n",
        "    w_sm = param.get_param('w_sm')\n",
        "\n",
        "    # compute loss and probs\n",
        "    loss = 0\n",
        "    probs = np.zeros((len(batch_x), 10))\n",
        "    h1_hat = np.dot(batch_x,w1)+b1\n",
        "    h1 = np.maximum(0,h1_hat)\n",
        "    h2_hat = np.dot(h1,w2)+b2\n",
        "    h2_hat_relu = np.maximum(0,h2_hat)\n",
        "\n",
        "    h2 = h1+h2_hat_relu\n",
        "    s = np.dot(h2,w_sm)\n",
        "    s_exp = np.exp(s)\n",
        "    probs = s_exp/np.sum(s_exp,axis = 1,keepdims =True)\n",
        "    log_probs = -np.log(probs[range(len(batch_x)),batch_y])\n",
        "    loss = np.sum(log_probs)/len(batch_x)\n",
        "\n",
        "    if not grad:\n",
        "        return loss, probs\n",
        "\n",
        "    # compute gradient\n",
        "    w1_grad = np.zeros_like(w1)\n",
        "    b1_grad = np.zeros_like(b1)\n",
        "    w2_grad = np.zeros_like(w2)\n",
        "    b2_grad = np.zeros_like(b2)\n",
        "    w_sm_grad = np.zeros_like(w_sm)\n",
        "    d_s = probs\n",
        "    d_s[range(len(h2)),batch_y] -= 1\n",
        "    d_s /= len(h2)\n",
        "    w_sm_grad = np.dot(h2.T,d_s)\n",
        "    d_h2 = np.dot(d_s,w_sm.T)\n",
        "    d_h2_hat = d_h2\n",
        "    d_h2_hat[h2_hat_relu<=0]=0\n",
        "    w2_grad = np.dot(h1.T,d_h2_hat)\n",
        "    b2_grad = np.sum(d_h2_hat,axis=0)\n",
        "    d_h1 = np.dot(d_h2_hat,w2.T) + np.dot(d_s,w_sm.T)\n",
        "    d_h1_hat= d_h1\n",
        "    d_h1_hat[h1<=0] =0\n",
        "    w1_grad = np.dot(batch_x.T,d_h1_hat)\n",
        "    b1_grad = np.sum(d_h1_hat,axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    param.accumlate_grad('w1', w1_grad)\n",
        "    param.accumlate_grad('b1', b1_grad)\n",
        "    param.accumlate_grad('w2', w2_grad)\n",
        "    param.accumlate_grad('b2', b2_grad)\n",
        "    param.accumlate_grad('w_sm', w_sm_grad)\n",
        "    return loss, probs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BCF5GRKvdGaw"
      },
      "source": [
        "### Loss & Gradient Check\n",
        "\n",
        "If all assertions are passed, it means you are good to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnkCUnV6cHlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use a prime number for batch size would make debugging easier\n",
        "bs = 7\n",
        "batch_x = train_x[:bs]\n",
        "batch_y = train_y[:bs]\n",
        "loss, _ = mlp_two_hidden_forward_and_backward(batch_x, batch_y, mlp_two_hidden)\n",
        "\n",
        "w1 = mlp_two_hidden.get_param('w1')\n",
        "b1 = mlp_two_hidden.get_param('b1')\n",
        "w2 = mlp_two_hidden.get_param('w2')\n",
        "b2 = mlp_two_hidden.get_param('b2')\n",
        "w_sm = mlp_two_hidden.get_param('w_sm')\n",
        "_w1 = torch.tensor(w1, dtype=torch.double, requires_grad=True)\n",
        "_b1 = torch.tensor(b1, dtype=torch.double, requires_grad=True)\n",
        "_w2 = torch.tensor(w2, dtype=torch.double, requires_grad=True)\n",
        "_b2 = torch.tensor(b2, dtype=torch.double, requires_grad=True)\n",
        "_w_sm = torch.tensor(w_sm, dtype=torch.double, requires_grad=True)\n",
        "_batch_x = torch.tensor(batch_x, dtype=torch.double, requires_grad=False)\n",
        "_batch_y = torch.tensor(batch_y, dtype=torch.long, requires_grad=False)\n",
        "\n",
        "_h1 = F.linear(_batch_x, _w1.T) + _b1\n",
        "_h1 = F.relu(_h1)\n",
        "\n",
        "_h2 = F.linear(_h1, _w2.T) + _b2\n",
        "_h2 = F.relu(_h2)\n",
        "_h2 = _h2 + _h1\n",
        "\n",
        "_logits = F.linear(_h2, _w_sm.T)\n",
        "_logprobs = F.log_softmax(_logits, dim=-1)\n",
        "_loss = -_logprobs[torch.arange(len(_batch_y)), _batch_y].mean()\n",
        "_loss.backward()\n",
        "assert np.isclose(loss, _loss.item())\n",
        "assert np.allclose(_w_sm.grad.numpy(), mlp_two_hidden.grad['w_sm'])\n",
        "assert np.allclose(_w2.grad.numpy(), mlp_two_hidden.grad['w2'])\n",
        "assert np.allclose(_b2.grad.numpy(), mlp_two_hidden.grad['b2'])\n",
        "assert np.allclose(_w1.grad.numpy(), mlp_two_hidden.grad['w1'])\n",
        "assert np.allclose(_b1.grad.numpy(), mlp_two_hidden.grad['b1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fNjUcsPoenly"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bnIsb-heqWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "9db1815f-9ce4-4878-c984-6758f8e184a0"
      },
      "source": [
        "BS = 50\n",
        "LR = 0.005\n",
        "NB_EPOCH = 20\n",
        "\n",
        "mlp_two_hidden = Parameters()\n",
        "mlp_two_hidden.set_param('w1', init_linear(NB_FEAT, NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('b1', np.zeros(NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('w2', init_linear(NB_FEAT // 2, NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('b2', np.zeros(NB_FEAT // 2))\n",
        "mlp_two_hidden.set_param('w_sm', init_linear(NB_FEAT // 2, 10))\n",
        "acc_list2 =[]\n",
        "acc_list2 = main_training(mlp_two_hidden, mlp_two_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, BS, LR, NB_EPOCH,acc_list2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|| 1/20 [00:15<04:50, 15.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train loss = 0.450 dev accuracy = 91.54%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|| 2/20 [00:30<04:34, 15.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train loss = 0.237 dev accuracy = 93.28%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|| 3/20 [00:45<04:19, 15.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train loss = 0.190 dev accuracy = 94.27%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|| 4/20 [01:01<04:04, 15.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train loss = 0.161 dev accuracy = 94.84%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|| 5/20 [01:16<03:48, 15.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train loss = 0.140 dev accuracy = 95.28%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|| 6/20 [01:31<03:33, 15.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 train loss = 0.124 dev accuracy = 95.59%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|| 7/20 [01:46<03:18, 15.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 train loss = 0.111 dev accuracy = 95.86%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|| 8/20 [02:02<03:03, 15.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 train loss = 0.101 dev accuracy = 96.06%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|| 9/20 [02:17<02:47, 15.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 train loss = 0.092 dev accuracy = 96.24%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|| 10/20 [02:32<02:32, 15.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 train loss = 0.084 dev accuracy = 96.43%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|| 11/20 [02:47<02:17, 15.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 train loss = 0.077 dev accuracy = 96.65%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|| 12/20 [03:02<02:01, 15.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11 train loss = 0.072 dev accuracy = 96.73%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|| 13/20 [03:18<01:46, 15.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 train loss = 0.066 dev accuracy = 96.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|| 14/20 [03:33<01:31, 15.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 13 train loss = 0.061 dev accuracy = 96.88%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|| 15/20 [03:48<01:16, 15.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 train loss = 0.057 dev accuracy = 96.96%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|| 16/20 [04:04<01:01, 15.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 15 train loss = 0.053 dev accuracy = 97.05%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|| 17/20 [04:19<00:46, 15.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 16 train loss = 0.050 dev accuracy = 97.08%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|| 18/20 [04:35<00:31, 15.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 17 train loss = 0.047 dev accuracy = 97.23%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|| 19/20 [04:50<00:15, 15.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 18 train loss = 0.044 dev accuracy = 97.26%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|| 20/20 [05:06<00:00, 15.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 19 train loss = 0.041 dev accuracy = 97.29%\n",
            "best dev accuracy = 97.29%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu8XTc-PSh6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "537a0679-a675-47e3-c655-d49fcc5d17c3"
      },
      "source": [
        "it=[i for i in range(NB_EPOCH)]\n",
        "plt.plot(it, acc_list2, color=\"r\", linestyle=\"-\", marker=\"^\", linewidth=1)\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKPhFRFJGwS8ikjIKfhGRlFHwi4ikzP8Hj49LBxUaOQoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiWnI6LFZIYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "e981de05-f6b0-4a31-bf82-42eb47bb6d55"
      },
      "source": [
        "it=[i for i in range(NB_EPOCH)]\n",
        "plt.plot(it, acc_list0, color=\"r\", linestyle=\"-\", linewidth=1,label='linear')\n",
        "plt.plot(it, acc_list1, color=\"b\", linestyle=\"-\", linewidth=1,label='single hidden')\n",
        "plt.plot(it, acc_list2, color=\"g\", linestyle=\"-\", linewidth=1,label='two hidden')\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4jEGQW/iEicUfCLiMQZBb+ISJz5///IPGGWJTZ3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAcJWKiNfZ_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def para_training(params: Parameters, forward_and_backward, train_x, train_y, dev_x, dev_y, batch_size, learning_rate, nb_epochs):#@\n",
        "    assert isinstance(params, Parameters)\n",
        "    step = 0\n",
        "    best_acc = 0\n",
        "    for epoch in tqdm(range(nb_epochs)):\n",
        "        train_loss = []\n",
        "        lr = learning_rate\n",
        "        for i in range(0, len(train_x), batch_size):\n",
        "            batch_x = train_x[i:i+batch_size]\n",
        "            batch_y = train_y[i:i+batch_size]\n",
        "\n",
        "            loss, probs = forward_and_backward(batch_x, batch_y, params)\n",
        "            params.apply_grad(lr)\n",
        "\n",
        "            train_loss.append(loss)\n",
        "            step += 1\n",
        "\n",
        "        accs = []\n",
        "        for i in range(0, len(dev_x), batch_size):\n",
        "            batch_x = dev_x[i:i+batch_size]\n",
        "            batch_y = dev_y[i:i+batch_size]\n",
        "\n",
        "            loss, probs = forward_and_backward(batch_x, batch_y, params, grad=False)\n",
        "            pred_y = probs.argmax(axis=1)\n",
        "            accs.append(pred_y == batch_y)\n",
        "        acc = np.mean(accs) * 100\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "    return best_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjpeyjRpd5L-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "576c9fcc-bd65-44a6-e976-2a78c37e1cd7"
      },
      "source": [
        "BS_list = [20,50]\n",
        "LR_list = [0.001,0.005]\n",
        "NB_EPOCH_list = [5,10]\n",
        "listpara = [0,0,0,0]\n",
        "best_acc = 0\n",
        "for b in BS_list:\n",
        "  for l in LR_list:\n",
        "    for n in NB_EPOCH_list:\n",
        "      acc = para_training(linear_classifier, linear_classifier_forward_and_backward, train_x, train_y, dev_x, dev_y, b, l, n)\n",
        "      if acc > best_acc:\n",
        "        best_acc =acc\n",
        "        listpara[0] = b\n",
        "        listpara[1] = l\n",
        "        listpara[2] = n\n",
        "        listpara[3] = 0\n",
        "      acc = para_training(mlp_single_hidden, mlp_single_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, b, l, n)\n",
        "      if acc > best_acc:\n",
        "        best_acc =acc\n",
        "        listpara[0] = b\n",
        "        listpara[1] = l\n",
        "        listpara[2] = n\n",
        "        listpara[3] = 1\n",
        "      acc = para_training(mlp_two_hidden, mlp_two_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, b, l, n)\n",
        "      if acc > best_acc:\n",
        "        best_acc =acc\n",
        "        listpara[0] = b\n",
        "        listpara[1] = l\n",
        "        listpara[2] = n\n",
        "        listpara[3] = 2\n",
        "print(listpara)\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 5/5 [00:03<00:00,  1.29it/s]\n",
            "100%|| 5/5 [01:28<00:00, 17.80s/it]\n",
            "100%|| 5/5 [02:22<00:00, 28.56s/it]\n",
            "100%|| 10/10 [00:07<00:00,  1.30it/s]\n",
            "100%|| 10/10 [02:57<00:00, 17.65s/it]\n",
            "100%|| 10/10 [04:46<00:00, 28.57s/it]\n",
            "100%|| 5/5 [00:04<00:00,  1.23it/s]\n",
            "100%|| 5/5 [01:28<00:00, 17.55s/it]\n",
            "100%|| 5/5 [02:22<00:00, 28.60s/it]\n",
            "100%|| 10/10 [00:07<00:00,  1.27it/s]\n",
            "100%|| 10/10 [02:54<00:00, 17.44s/it]\n",
            "100%|| 10/10 [04:46<00:00, 28.52s/it]\n",
            "100%|| 5/5 [00:04<00:00,  1.15it/s]\n",
            "100%|| 5/5 [00:45<00:00,  9.19s/it]\n",
            "100%|| 5/5 [01:14<00:00, 14.80s/it]\n",
            "100%|| 10/10 [00:08<00:00,  1.15it/s]\n",
            "100%|| 10/10 [01:33<00:00,  9.23s/it]\n",
            "100%|| 10/10 [02:29<00:00, 14.87s/it]\n",
            "100%|| 5/5 [00:04<00:00,  1.11it/s]\n",
            "100%|| 5/5 [00:47<00:00,  9.37s/it]\n",
            "100%|| 5/5 [01:15<00:00, 15.09s/it]\n",
            "100%|| 10/10 [00:08<00:00,  1.17it/s]\n",
            "100%|| 10/10 [01:31<00:00,  9.12s/it]\n",
            "100%|| 10/10 [02:28<00:00, 14.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[20, 0.001, 5, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyc6MtXjtAL5",
        "colab_type": "text"
      },
      "source": [
        "When the batch size is 20, learning rate is 0.001 and the epoch is  5 , the accuracy of single hidden layer is the best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvHIY7ycfZMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "fe71d453-459c-48d4-971d-dba3e8000efe"
      },
      "source": [
        "acc_list4 =[]\n",
        "if listpara[3] ==0:\n",
        "  acc_list4 = main_training(mlp_two_hidden, mlp_two_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, listpara[0], listpara[1], listpara[2],acc_list4)\n",
        "if listpara[3] ==1:\n",
        "  acc_list4 = main_training(mlp_two_hidden, mlp_two_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, listpara[0], listpara[1], listpara[2],acc_list4)\n",
        "if listpara[3] ==2:\n",
        "  acc_list4 = main_training(mlp_two_hidden, mlp_two_hidden_forward_and_backward, train_x, train_y, dev_x, dev_y, listpara[0], listpara[1], listpara[2],acc_list4)\n",
        "it=[i for i in range(listpara[2])]\n",
        "plt.plot(it, acc_list4, color=\"r\", linestyle=\"-\", linewidth=1,label='best')\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|| 1/5 [00:28<01:55, 28.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train loss = 0.001 dev accuracy = 98.17%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|| 2/5 [00:57<01:26, 28.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train loss = 0.001 dev accuracy = 98.17%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|| 3/5 [01:26<00:57, 28.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train loss = 0.001 dev accuracy = 98.17%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|| 4/5 [01:55<00:28, 28.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train loss = 0.001 dev accuracy = 98.17%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|| 5/5 [02:24<00:00, 28.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 train loss = 0.001 dev accuracy = 98.17%\n",
            "best dev accuracy = 98.17%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}