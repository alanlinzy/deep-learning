{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"L_9_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"58ba04fff0d14712b66897b4662d37a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a87e3da432624547981ae81e99a1e06f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9621936821b545b593be299b9b514c70","IPY_MODEL_cb088937d0da41ac99cacb5eb2642467"]}},"a87e3da432624547981ae81e99a1e06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9621936821b545b593be299b9b514c70":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9141771a84e940b5b1ac87e42e990333","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dfcbc80da2e04861a7693e53c6ba0b2f"}},"cb088937d0da41ac99cacb5eb2642467":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5810940d63a04f9d9a36fb7c16c7dcd3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"9920512it [00:01, 9090543.15it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_254fdfa47d1047ea98ada1f761a71d48"}},"9141771a84e940b5b1ac87e42e990333":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dfcbc80da2e04861a7693e53c6ba0b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5810940d63a04f9d9a36fb7c16c7dcd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"254fdfa47d1047ea98ada1f761a71d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afd13bfb567c40a09c0b16b140c61e57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_035a2dfbc33641fcb98aec1de8870faf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b5af35af31814b8196d992c97a6fc051","IPY_MODEL_def546f117f14579ab731b8ead797a61"]}},"035a2dfbc33641fcb98aec1de8870faf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5af35af31814b8196d992c97a6fc051":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e4408d67d6fa42fe83a9d3f3386566bd","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc5124ddd90a4ed0aa4a6ad9a8f69c1d"}},"def546f117f14579ab731b8ead797a61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7d6f2709df2b4aebacbbd5c3d030eec0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"32768it [00:00, 107137.22it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_938b4fe13e0e4a19ac00f425a79a5195"}},"e4408d67d6fa42fe83a9d3f3386566bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc5124ddd90a4ed0aa4a6ad9a8f69c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d6f2709df2b4aebacbbd5c3d030eec0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"938b4fe13e0e4a19ac00f425a79a5195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0eaad983c225497cad477345119b4ada":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f13079e87f964a429872b161bca643e0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95cd85d5d3d74e0d98870f7621179154","IPY_MODEL_6a0c79c4ecec4dd8b1b3e3b2be22deaa"]}},"f13079e87f964a429872b161bca643e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95cd85d5d3d74e0d98870f7621179154":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5470e726c79e47febb819fd452f47072","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8022401c3f8435fa376dc1b3bc7ebc0"}},"6a0c79c4ecec4dd8b1b3e3b2be22deaa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d7bf726762041a9b2d50391afc95176","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"1654784it [00:00, 2336894.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b418d7a305834604bcb5eef59635b766"}},"5470e726c79e47febb819fd452f47072":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8022401c3f8435fa376dc1b3bc7ebc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d7bf726762041a9b2d50391afc95176":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b418d7a305834604bcb5eef59635b766":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9bca837a908428797edb542adb883e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_764cb7064bd64e949bc3059e2538c04e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b780958d541d4979958aee3205b8061e","IPY_MODEL_71c27eecf5324b029e8883bdf9d8675e"]}},"764cb7064bd64e949bc3059e2538c04e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b780958d541d4979958aee3205b8061e":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f326f04ce7254e3d9b9e6cd1a17921a5","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6f30ac538ca44ec9543fae7aa6329d4"}},"71c27eecf5324b029e8883bdf9d8675e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a439bf0634bd4901acbc28d3dc70ef30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"8192it [00:00, 34676.51it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e54384bc55946baa0ee153a3b75d0af"}},"f326f04ce7254e3d9b9e6cd1a17921a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c6f30ac538ca44ec9543fae7aa6329d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a439bf0634bd4901acbc28d3dc70ef30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e54384bc55946baa0ee153a3b75d0af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t0-VXSCM7avd"},"source":["# L-9-1: Inverse Classroom: It’s not working! Help!\n","\n","These exercises will give you some debugging experience on problems typically found when doing machine learning in practice.\n","\n","**Outline**\n","\n","0. General Set-up\n","1. Debugging A Bad Training Set-up\n","2. Image Segmentation with DICE Loss\n","3. Fixing the Data-Processing Pipeline\n","4. Test Performance is Too Good!"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3secgg798917"},"source":["## 0. General Set-up\n","\n","Here we provide general code set-up: package requirements, train-loaders, etc."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8ocl9Mfl8LH6","colab":{}},"source":["## Some general imports we may need:\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.datasets as dataset\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uG5SflgE9eVz"},"source":["Make sure GPU is enabled: In Colab, at the top, \n","\n","click `Runtime` -> `Change runtime type` -> `Hardware Accelerator` -> `GPU`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rFFtp9BmLxo9","colab":{}},"source":["gpu_boole = torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IAb83ZuC52lC","colab":{"base_uri":"https://localhost:8080/","height":383,"referenced_widgets":["58ba04fff0d14712b66897b4662d37a6","a87e3da432624547981ae81e99a1e06f","9621936821b545b593be299b9b514c70","cb088937d0da41ac99cacb5eb2642467","9141771a84e940b5b1ac87e42e990333","dfcbc80da2e04861a7693e53c6ba0b2f","5810940d63a04f9d9a36fb7c16c7dcd3","254fdfa47d1047ea98ada1f761a71d48","afd13bfb567c40a09c0b16b140c61e57","035a2dfbc33641fcb98aec1de8870faf","b5af35af31814b8196d992c97a6fc051","def546f117f14579ab731b8ead797a61","e4408d67d6fa42fe83a9d3f3386566bd","bc5124ddd90a4ed0aa4a6ad9a8f69c1d","7d6f2709df2b4aebacbbd5c3d030eec0","938b4fe13e0e4a19ac00f425a79a5195","0eaad983c225497cad477345119b4ada","f13079e87f964a429872b161bca643e0","95cd85d5d3d74e0d98870f7621179154","6a0c79c4ecec4dd8b1b3e3b2be22deaa","5470e726c79e47febb819fd452f47072","c8022401c3f8435fa376dc1b3bc7ebc0","0d7bf726762041a9b2d50391afc95176","b418d7a305834604bcb5eef59635b766","a9bca837a908428797edb542adb883e6","764cb7064bd64e949bc3059e2538c04e","b780958d541d4979958aee3205b8061e","71c27eecf5324b029e8883bdf9d8675e","f326f04ce7254e3d9b9e6cd1a17921a5","c6f30ac538ca44ec9543fae7aa6329d4","a439bf0634bd4901acbc28d3dc70ef30","4e54384bc55946baa0ee153a3b75d0af"]},"outputId":"45c7f930-41e2-42a5-9c32-fce497bf8bda","executionInfo":{"status":"ok","timestamp":1583502340541,"user_tz":300,"elapsed":3721,"user":{"displayName":"Craig Guo","photoUrl":"","userId":"05010328137796851885"}}},"source":["## Basic dataloading for MNIST.\n","# Just to make sure it works for the rest of this notebook.\n","training = dataset.MNIST(root ='./data', transform=transforms.ToTensor(), train=True, download=True)\n","testing =  dataset.MNIST(root ='./data', transform = transforms.ToTensor(), train=False, download=True)\n","train_loader = torch.utils.data.DataLoader(dataset=training, batch_size = 128, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=testing, batch_size = 128, shuffle=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58ba04fff0d14712b66897b4662d37a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afd13bfb567c40a09c0b16b140c61e57","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0eaad983c225497cad477345119b4ada","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9bca837a908428797edb542adb883e6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iNegXCYN52aB","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"d99a2872-8901-4e1e-89f3-76eb39b79163","executionInfo":{"status":"ok","timestamp":1583502357227,"user_tz":300,"elapsed":1180,"user":{"displayName":"Craig Guo","photoUrl":"","userId":"05010328137796851885"}}},"source":["## Plotting data to make sure it is correct:\n","x,y = next(iter(train_loader))\n","plt.imshow(x[0][0].cpu().data.numpy()) #plotting first channel of first image of MNIST\n","plt.show()\n","print('Label', y[0])"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQdiBJAg7kARhB5Ig7EAS/w933SglQZQOWgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Label tensor(5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h8UeQcnW51sS"},"source":["If you see an image of one of training samples above, then everything is working correctly for the next section.\n","\n","**Some quick info about this dataset before starting:**\n","* We will be using the MNIST dataset, a handwritten digit dataset consisting of 10 classes, digits 0 through 9. MNIST consists of 60k training samples and 10k test samples. The images are of shape 28 x 28 (only one channel, grayscale).\n","* Typically MNIST is used as a baseline classification task for prototyping research ideas. In contemporary research, it is usually considered too easy for bonafide ideas to be validated on by itself, instead harder baselines are additionally provided. \n","* For our purposes though, this dataset works well for this classroom setting and will provide us with some basic debugging experience."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xf98O6-QAWpr"},"source":["## 1. Debugging A Bad Training Set-Up"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1JogukGYAhdv"},"source":["* For this section, you are given a training loop for MNIST. \n","* The loss curve doesn't look correct though, what is the issue?\n","* **Deliverables:** \n","  * You will have to debug codeblocks below to achieve a good loss curve.\n","  * Explain what the problem or problems you found, what you ended up addressing, changing, or adding\n","  * Output a final test accuracy score of 90% or above in 2 epochs of training or less."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XefTpBSaHwvj"},"source":["**Defining the model:**\n","Here we define a simple multi-layer perceptron (MLP) model, with two hidden layers and relu activations.\n","\n","**NOTE: Although you are free to play around with the Net model definition, it's not needed to \"solve\" this notebook.**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cSMBOq6OAUek","colab":{}},"source":["class Net(nn.Module):\n","  def __init__(self, input_size, width, num_classes):\n","    super(Net, self).__init__()\n","\n","    ##feedfoward layers:\n","    self.ff1 = nn.Linear(input_size, width) #input\n","\n","    self.ff2 = nn.Linear(width, width) #hidden layers\n","    self.ff3 = nn.Linear(width, width)\n","\n","    self.ff_out = nn.Linear(width, num_classes) #logit layer     \n","\n","    ##activations:\n","    self.relu = nn.ReLU()\n","\n","    #other activations:\n","    self.tanh = nn.Tanh()\n","    self.sigmoid = nn.Sigmoid()\n","\n","    ## Some normalization functions.\n","    ## Feel free to add them into the forward pass if you like.\n","    \n","    #dropout:\n","    self.do = nn.Dropout()\n","\n","    #batch-normalization:\n","    self.bn1 = nn.BatchNorm1d(width)\n","    self.bn2 = nn.BatchNorm1d(width)\n","    self.bn3 = nn.BatchNorm1d(width)\n","\n","                \n","  def forward(self, input_data):\n","    out = self.relu(self.ff1(input_data)) \n","    out = self.relu(self.ff2(out)) \n","    out = self.relu(self.ff3(out))\n","    out = nn.functional.softmax(self.ff_out(out),dim = 0)\n","    return out #returns class probabilities for each image\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iVIM33iCI0-2"},"source":["**Instantiating the model:** we instantiate the model with a width of 500 and 10 classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PcXASArYIsvj","colab":{}},"source":["net = Net(input_size = 784, width = 500, num_classes = 10)\n","if gpu_boole:\n","  net = net.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Sda-76CdJnlX"},"source":["**Defining the optimizer:** we set the optimization procedure as stochastic gradient descent with various parameters. We also define our loss function."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JNOhErrSJj3B","colab":{}},"source":["optimizer = torch.optim.SGD(net.parameters(), lr = 0.9, momentum = 0.9, weight_decay = 0.0000001, dampening = 0.000002, nesterov = False)\n","loss_metric = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G5u9uAJZKVNB"},"source":["**Defining dataset loaders:** here, we define the dataset loaders with a specific batch size of 128 and basic tensor transformation / preprocessing:\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cHSq5YEyK452","colab":{}},"source":["training = dataset.MNIST(root ='./data', transform=transforms.ToTensor(), train=True, download=True)\n","testing =  dataset.MNIST(root ='./data', transform = transforms.ToTensor(), train=False, download=True)\n","train_loader = torch.utils.data.DataLoader(dataset=training, batch_size = 128, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=testing, batch_size = 128, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uAd34-RlM_a4"},"source":["**Defining training and test loss and accuracy functions:** These functions will be useful in our training loop to view are training and test loss/accuracy at each epoch."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1X7K9TaPNMDe","colab":{}},"source":["def train_eval(verbose = 1):\n","    correct = 0\n","    total = 0\n","    loss_sum = 0\n","    for images, labels in train_loader:\n","        if gpu_boole:\n","            images, labels = images.cuda(), labels.cuda()\n","        images = images.view(-1, 28*28)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.float() == labels.float()).sum()\n","\n","        loss_sum += loss_metric(outputs,labels)\n","        \n","    if verbose:\n","        print('Train accuracy: %f %%' % (100 * correct / total))\n","        print('Train loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n","\n","    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total\n","    \n","def test_eval(verbose = 1):\n","    correct = 0\n","    total = 0\n","    loss_sum = 0\n","    for images, labels in test_loader:\n","        if gpu_boole:\n","            images, labels = images.cuda(), labels.cuda()\n","        images = images.view(-1, 28*28)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.float() == labels.float()).sum()\n","\n","        loss_sum += loss_metric(outputs,labels)\n","\n","    if verbose:\n","        print('Test accuracy: %f %%' % (100 * correct / total))\n","        print('Test loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n","\n","        \n","    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"99oTqwXDK_a3"},"source":["**Traning loop:** here, we give the training loop. A number of epochs is set. Loss is recorded and plotted at the end.\n","\n","**IMPORTANT NOTE:** For re-running this code cell, if you encounter nan loss, you will need to reinstantiate your model and optimizer by re-running the \"Instantiating the model:\" and \"Defining the optimizer:\" code cells above."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fwDUdRlOLUwG","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"babacd36-8d60-4a81-ef71-531da02da550"},"source":["#re-initializing network weights:\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","        torch.nn.init.xavier_uniform(m.weight.data)\n","\n","weights_init(net)\n","\n","#number of epochs to train for:\n","epochs = 2\n","\n","#defining batch train loss recording arrays for later visualization/plotting:\n","loss_batch_store = []\n","\n","print(\"Starting Training\")\n","#training loop:\n","for epoch in range(epochs):\n","  time1 = time.time() #timekeeping\n","\n","  for i, (x,y) in enumerate(train_loader):\n","\n","    #reshaping to flat shape:\n","    x = x.view(-1,28*28)\n","\n","    if gpu_boole:\n","      x = x.cuda()\n","      y = y.cuda()\n","\n","    #loss calculation and gradient update:\n","\n","    if i > 0 or epoch > 0:\n","      optimizer.zero_grad()\n","    outputs = net.forward(x)\n","    loss = loss_metric(outputs,y)\n","    loss.backward()\n","\n","    if i > 0 or epoch > 0:\n","      loss_batch_store.append(loss.cpu().data.numpy().item())\n","                  \n","    ##performing update:\n","    optimizer.step()\n","\n","  print(\"Epoch\",epoch+1,':')\n","  train_perc, train_loss = train_eval()\n","  test_perc, test_loss = test_eval()\n","\n","  time2 = time.time() #timekeeping\n","  print('Elapsed time for epoch:',time2 - time1,'s')\n","  print('ETA of completion:',(time2 - time1)*(epochs - epoch - 1)/60,'minutes')\n","  print()\n","\n","## Plotting batch-wise train loss curve:\n","plt.plot(loss_batch_store, '-o', label = 'train_loss', color = 'blue')\n","plt.xlabel('Minibatch Number')\n","plt.ylabel('Sample-wise Loss At Last minibatch')\n","plt.legend()\n","plt.show()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting Training\n","Epoch 1 :\n","Train accuracy: 74.000000 %\n","Train loss: 0.017471\n","Test accuracy: 77.000000 %\n","Test loss: 0.017617\n","Elapsed time for epoch: 10.884570837020874 s\n","ETA of completion: 0.1814095139503479 minutes\n","\n","Epoch 2 :\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"A4SlBnqAUs3r"},"source":["**What went wrong?**\n","\n","* The loss curve doesn't look right (no clear, gradual decrease in train loss over time), and your train and test accuracy are terrible and stuck at around random chance. Worse yet, your loss is returning nan (\"not a number\")!\n","\n","* Go through the codeblocks above to try and debug the problem. Is optimization procedure correcly specified? Are hyperparameters reasonable? Should batch-size be increased or decreased? Should initialization be done differently?\n","\n","* Your job will be to make adjustments, figure out any problems that may be occurring, and make the output give a test accuracy of 90% or above (for 2 epochs of training or less)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aYqrbUbNVgQU"},"source":["**Explain your changes, additions, and adjustments below. Describe what led to a better training procedure and why:**\n","\n","[Your text here]"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hm9cN-LlP6V2","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}