{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0-VXSCM7avd"
   },
   "source": [
    "# L-9-4: Inverse Classroom: Itâ€™s not working! Help!\n",
    "\n",
    "These exercises will give you some debugging experience on problems typically found when doing machine learning in practice.\n",
    "\n",
    "**Outline**\n",
    "\n",
    "0. General Set-up\n",
    "1. Debugging A Bad Training Set-up\n",
    "2. Image Segmentation with DICE Loss\n",
    "3. Fixing the Data-Processing Pipeline\n",
    "4. Test Performance is Too Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3secgg798917"
   },
   "source": [
    "## 0. General Set-up\n",
    "\n",
    "Here we provide general code set-up: package requirements, train-loaders, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ocl9Mfl8LH6"
   },
   "outputs": [],
   "source": [
    "## Some general imports we may need:\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uG5SflgE9eVz"
   },
   "source": [
    "Make sure GPU is enabled: In Colab, at the top, \n",
    "\n",
    "click `Runtime` -> `Change runtime type` -> `Hardware Accelerator` -> `GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFFtp9BmLxo9"
   },
   "outputs": [],
   "source": [
    "gpu_boole = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bNXCy0voYj8"
   },
   "source": [
    "##4. Test Performance is Too Good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcASb2_cPea6"
   },
   "source": [
    "* Like in L-9-1 and L-9-3, you are given a training pipeline for MNIST.\n",
    "* In this case, we are doing binary classification on a subset on the digits: 0's and 8's.\n",
    "* The test accuracy is close to 100% after 1 epoch. Great!\n",
    "* **Deliverables:** Identify and correct possible problems with the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov_IbOqHQ5Vc"
   },
   "source": [
    "**Defining the model and optimizer:**\n",
    "We define the model and optimizer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1Zpa5BpocMw"
   },
   "outputs": [],
   "source": [
    "## Defining the model:\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, width, num_classes):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    ##feedfoward layers:\n",
    "    self.ff1 = nn.Linear(input_size, width) #input\n",
    "\n",
    "    self.ff2 = nn.Linear(width, width) #hidden layers\n",
    "    self.ff3 = nn.Linear(width, width)\n",
    "\n",
    "    self.ff_out = nn.Linear(width, num_classes) #logit layer     \n",
    "\n",
    "    ##activations:\n",
    "    self.relu = nn.ReLU()\n",
    "                \n",
    "  def forward(self, input_data):\n",
    "    out = self.relu(self.ff1(input_data)) \n",
    "    out = self.relu(self.ff2(out)) \n",
    "    out = self.relu(self.ff3(out))\n",
    "    out = self.ff_out(out)\n",
    "    return out #returns class probabilities for each image\n",
    "\n",
    "net = Net(input_size = 784, width = 500, num_classes = 2)\n",
    "if gpu_boole:\n",
    "  net = net.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
    "loss_metric = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0M9EK9KRLPn"
   },
   "source": [
    "**Data loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0CCXIB2Q-gD"
   },
   "outputs": [],
   "source": [
    "#Downloading and unzipping MNIST data files:\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "!gunzip t*-ubyte.gz -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wZEG_2eRUre"
   },
   "outputs": [],
   "source": [
    "##Loading files into numpy arrays:\n",
    "def read_idx(filename, boole=0):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        if boole:\n",
    "          return np.fromstring(f.read(), dtype=np.uint8).reshape(shape).astype(np.float32)*10     \n",
    "        else:\n",
    "          return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "xtrain = read_idx('train-images-idx3-ubyte', 1)\n",
    "xtest = read_idx('t10k-images-idx3-ubyte', 1)\n",
    "ytrain = read_idx('train-labels-idx1-ubyte')\n",
    "ytest = read_idx('t10k-labels-idx1-ubyte')\n",
    "\n",
    "## Splitting into 0's and 8's:\n",
    "xdata = np.concatenate([xtrain,xtest],axis=0)\n",
    "ydata = np.concatenate([ytrain,ytest],axis=0)\n",
    "\n",
    "inds_0s = ydata == 0\n",
    "inds_8s = ydata == 8\n",
    "ydata[inds_0s] = 1\n",
    "ydata[inds_8s] = 0\n",
    "xdata = np.concatenate([xdata[inds_0s],xdata[inds_8s]],axis=0)\n",
    "ydata = np.concatenate([ydata[inds_0s],ydata[inds_8s]],axis=0)\n",
    "\n",
    "N = int(round(xdata.shape[0]*0.9)) #90-10 train-test split\n",
    "xtrain = xdata[:N]\n",
    "xtest = xdata[N:]\n",
    "ytrain = ydata[:N]\n",
    "ytest = ydata[N:]\n",
    "\n",
    "xtrain = torch.Tensor(xtrain) / 255.0\n",
    "ytrain = torch.Tensor(ytrain).long()\n",
    "xtest = torch.Tensor(xtest) / 255.0\n",
    "ytest = torch.Tensor(ytest).long()\n",
    "\n",
    "## data_loaders:\n",
    "train = torch.utils.data.TensorDataset(xtrain, ytrain)\n",
    "test = torch.utils.data.TensorDataset(xtest, ytest)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Mm3Xb25RqVD"
   },
   "source": [
    "**Defining training and test loss and accuracy functions:** These functions will be useful in our training loop to view are training and test loss/accuracy at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-9LggnZRib5"
   },
   "outputs": [],
   "source": [
    "def train_eval(verbose = 1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    for images, labels in train_loader:\n",
    "        if gpu_boole:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.float() == labels.float()).sum()\n",
    "\n",
    "        loss_sum += loss_metric(outputs,labels)\n",
    "        \n",
    "    if verbose:\n",
    "        print('Train accuracy: %f %%' % (100 * correct / total))\n",
    "        print('Train loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n",
    "\n",
    "    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total\n",
    "    \n",
    "def test_eval(verbose = 1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    for images, labels in test_loader:\n",
    "        if gpu_boole:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.float() == labels.float()).sum()\n",
    "\n",
    "        loss_sum += loss_metric(outputs,labels)\n",
    "\n",
    "    if verbose:\n",
    "        print('Test accuracy: %f %%' % (100 * correct / total))\n",
    "        print('Test loss: %f' % (loss_sum.cpu().data.numpy().item() / total))\n",
    "\n",
    "    return 100.0 * correct / total, loss_sum.cpu().data.numpy().item() / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbY7GMJSRvfG"
   },
   "source": [
    "**Traning loop:** here, we give the training loop. A number of epochs is set. Loss is recorded and plotted at the end.\n",
    "\n",
    "**IMPORTANT NOTE:** For re-running this code cell, if you encounter nan loss, you will need to reinstantiate your model and optimizer by re-running the \"Defining the model and optimizer:\" code cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiNJJPNNRsUc"
   },
   "outputs": [],
   "source": [
    "#re-initializing network weights:\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data)\n",
    "\n",
    "weights_init(net)\n",
    "\n",
    "#number of epochs to train for:\n",
    "epochs = 5\n",
    "\n",
    "#defining batch train loss recording arrays for later visualization/plotting:\n",
    "loss_batch_store = []\n",
    "test_loss_store = []\n",
    "\n",
    "print(\"Starting Training\")\n",
    "#training loop:\n",
    "for epoch in range(epochs):\n",
    "  time1 = time.time() #timekeeping\n",
    "\n",
    "  for i, (x,y) in enumerate(train_loader):\n",
    "\n",
    "    x = x.view(-1,28*28)\n",
    "\n",
    "    if gpu_boole:\n",
    "      x = x.cuda()\n",
    "      y = y.cuda()\n",
    "\n",
    "    #loss calculation and gradient update:\n",
    "\n",
    "    if i > 0 or epoch > 0:\n",
    "      optimizer.zero_grad()\n",
    "    outputs = net.forward(x)\n",
    "    loss = loss_metric(outputs,y)\n",
    "    loss.backward()\n",
    "\n",
    "    if i > 0 or epoch > 0:\n",
    "      loss_batch_store.append(loss.cpu().data.numpy().item())\n",
    "                  \n",
    "    ##performing update:\n",
    "    optimizer.step()\n",
    "\n",
    "  print(\"Epoch\",epoch+1,':')\n",
    "  train_perc, train_loss = train_eval()\n",
    "  test_perc, test_loss = test_eval()\n",
    "  test_loss_store.append(test_loss)\n",
    "\n",
    "  time2 = time.time() #timekeeping\n",
    "  print('Elapsed time for epoch:',time2 - time1,'s')\n",
    "  print('ETA of completion:',(time2 - time1)*(epochs - epoch - 1)/60,'minutes')\n",
    "  print()\n",
    "\n",
    "## Plotting batch-wise train loss curve:\n",
    "plt.plot(loss_batch_store, '-o', label = 'train_loss', color = 'blue')\n",
    "plt.xlabel('Minibatch Number')\n",
    "plt.ylabel('Sample-wise Loss At Last minibatch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Plotting epoch-wise test loss curve:\n",
    "plt.plot(test_loss_store, '-o', label = 'test_loss', color = 'orange')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Sample-wise Loss At Last epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLnwMVk5VxE5"
   },
   "source": [
    "**Describe your modifications.**\n",
    "* What modifications, if any, did you make to the code?\n",
    "* Make a case for why you did or did not make any changes, and how the end results differed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuf6KlmYS6jx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "L_9_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
